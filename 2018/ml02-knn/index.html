
<!DOCTYPE html>
<html lang="zh-CN" class="loading">
<head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>机器学习之 k 近邻算法 - 常也</title>
    <meta name="apple-mobile-web-app-capable" content="yes" />
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="google" content="notranslate" />
    <meta name="keywords" content="Fechin,"> 
    <meta name="description" content="
什么是 k 近邻算法k 近邻（k-Nearest Neighbor，kNN）是机器学习中相对简单且容易理解的算法，是分类数据最简单有效的算法，它基于实例学习，我们必须用最真实的样本数据对模型进行训,"> 
    <meta name="author" content="Fechin"> 
    <link rel="alternative" href="atom.xml" title="常也" type="application/atom+xml"> 
    <link rel="icon" href="/img/favicon.png"> 
    
<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">

    
    
    <meta name="twitter:card" content="summary"/>
    <meta name="twitter:title" content="机器学习之 k 近邻算法 - 常也"/>
    <meta name="twitter:description" content="
什么是 k 近邻算法k 近邻（k-Nearest Neighbor，kNN）是机器学习中相对简单且容易理解的算法，是分类数据最简单有效的算法，它基于实例学习，我们必须用最真实的样本数据对模型进行训,"/>
    
    
    
    
    <meta property="og:site_name" content="常也"/>
    <meta property="og:type" content="object"/>
    <meta property="og:title" content="机器学习之 k 近邻算法 - 常也"/>
    <meta property="og:description" content="
什么是 k 近邻算法k 近邻（k-Nearest Neighbor，kNN）是机器学习中相对简单且容易理解的算法，是分类数据最简单有效的算法，它基于实例学习，我们必须用最真实的样本数据对模型进行训,"/>
    
<link rel="stylesheet" href="/css/diaspora.css">

    <script>window.searchDbPath = "/search.xml";</script>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Source+Code+Pro&display=swap" rel="stylesheet">
<meta name="generator" content="Hexo 5.4.0"></head>

<body class="loading">
    <span id="config-title" style="display:none">常也</span>
    <div id="loader"></div>
    <div id="single">
    <div id="top" style="display: block;">
    <div class="bar" style="width: 0;"></div>
    <a class="iconfont icon-home image-icon" href="javascript:;" data-url="http://fech.in"></a>
    <div title="播放/暂停" class="iconfont icon-play"></div>
    <h3 class="subtitle">机器学习之 k 近邻算法</h3>
    <div class="social">
        <div>
            <div class="share">
                <a title="获取二维码" class="iconfont icon-scan" href="javascript:;"></a>
            </div>
            <div id="qr"></div>
        </div>
    </div>
    <div class="scrollbar"></div>
</div>

    <div class="section">
        <div class="article">
    <div class='main'>
        <h1 class="title">机器学习之 k 近邻算法</h1>
        <div class="stuff">
            <span>六月 03, 2018</span>
            
  <ul class="post-tags-list" itemprop="keywords"><li class="post-tags-list-item"><a class="post-tags-list-link" href="/tags/%E6%9C%80%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95/" rel="tag">最近邻算法</a></li><li class="post-tags-list-item"><a class="post-tags-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a></li><li class="post-tags-list-item"><a class="post-tags-list-link" href="/tags/%E7%AE%97%E6%B3%95/" rel="tag">算法</a></li></ul>


        </div>
        <div class="content markdown">
            <p><img src="/static/images/ml02/knnheader.png" alt="kNN algorithm"></p>
<h4 id="什么是-k-近邻算法"><a href="#什么是-k-近邻算法" class="headerlink" title="什么是 k 近邻算法"></a>什么是 k 近邻算法</h4><p>k 近邻（k-Nearest Neighbor，kNN）是机器学习中相对简单且容易理解的算法，是分类数据最简单有效的算法，它基于实例学习，我们必须用最真实的样本数据对模型进行训练，以便预测出的结果更具参考意义。</p>
<p>简单地说，<strong>k 近邻算法采用测量不同特征值之间的距离方法进行分类</strong>。这句话简单也不简单。更通俗易懂的理解，所谓“物以类聚，人以群分”，kNN 认为彼此相隔最近的点为一类。周围的对象是什么类别，我就是什么类别。如果你的朋友都开法拉利、保时捷等跑车，那么在 kNN 眼你，你也是有钱人，也开豪车。</p>
<h4 id="算法实现"><a href="#算法实现" class="headerlink" title="算法实现"></a>算法实现</h4><p>本文不打算用代码实现一个 k 近邻算法，感兴趣的可以查阅资料研究其实现，但我们必须知道算法的实现步骤。</p>
<blockquote>
<p>对未知类型的数据集中的每个点依次执行如下操作：</p>
<ol>
<li>计算已知类别数据集中的点与当前点之间的距离；</li>
<li>按距离递增次序排序；</li>
<li>选取与当前点距离最小的 k 个点；</li>
<li>确认前 k 个点出现频率最高的类别作为当前点的预测分类；</li>
</ol>
</blockquote>
<p>接下来，举个栗子带大家更好的理解 kNN 算法。如图，有黄色的管理人才，深蓝色的架构师，以及未知的天蓝色。</p>
<p><img src="/static/images/ml02/kNNsample.jpg" alt="kNN Sample"></p>
<p>当我们需要对员工进行技术和管理两个培养方向分类时，可能会考虑到他们的情商、沟通、技能、协作、远见、解决问题等能力。由于人类大脑的限制，我们只能处理三维以下的事务，这里只列举两个特征“情商”和“技能”评分，假设情商分高可作为管理人才来培养，技能分高作为架构师人才来培养。</p>
<p>我们拿到了七个样本数据，每一个样本带有情商和技能特征，以及对应的标签，他们分布在图中的数据如下：</p>
<table>
<thead>
<tr>
<th align="center">技能</th>
<th align="center">情商</th>
<th align="center">培养方向</th>
</tr>
</thead>
<tbody><tr>
<td align="center">43</td>
<td align="center">92</td>
<td align="center">管理</td>
</tr>
<tr>
<td align="center">60</td>
<td align="center">88</td>
<td align="center">管理</td>
</tr>
<tr>
<td align="center">69</td>
<td align="center">80</td>
<td align="center">架构师</td>
</tr>
<tr>
<td align="center">66</td>
<td align="center">78</td>
<td align="center">管理</td>
</tr>
<tr>
<td align="center">88</td>
<td align="center">50</td>
<td align="center">架构师</td>
</tr>
<tr>
<td align="center">80</td>
<td align="center">91</td>
<td align="center">管理</td>
</tr>
<tr>
<td align="center">96</td>
<td align="center">35</td>
<td align="center">架构师</td>
</tr>
<tr>
<td align="center">68</td>
<td align="center">80</td>
<td align="center">？</td>
</tr>
</tbody></table>
<p>现在的需求是通过天蓝色的特征值预测他更适合的培养方向，按照 kNN 算法的实现步骤，计算出天蓝色特征与样本集的距离。计算二维平面上两点 a(x1,y1) 与 b(x2,y2) 间的欧氏距离<br><img src="/static/images/ml02/EuclideanDistanceGraphic01.jpg" alt="Euclidean Distance"></p>
<p>按距离升序排序之后结果如下：</p>
<table>
<thead>
<tr>
<th align="center">技能</th>
<th align="center">情商</th>
<th align="center">欧式距离↑</th>
<th align="center">培养方向</th>
</tr>
</thead>
<tbody><tr>
<td align="center">69</td>
<td align="center">80</td>
<td align="center">1.0</td>
<td align="center">架构师</td>
</tr>
<tr>
<td align="center">66</td>
<td align="center">78</td>
<td align="center">2.83</td>
<td align="center">管理</td>
</tr>
<tr>
<td align="center">60</td>
<td align="center">88</td>
<td align="center">11.31</td>
<td align="center">管理</td>
</tr>
<tr>
<td align="center">80</td>
<td align="center">91</td>
<td align="center">16.27</td>
<td align="center">管理</td>
</tr>
<tr>
<td align="center">43</td>
<td align="center">92</td>
<td align="center">27.73</td>
<td align="center">管理</td>
</tr>
<tr>
<td align="center">88</td>
<td align="center">50</td>
<td align="center">36.06</td>
<td align="center">架构师</td>
</tr>
<tr>
<td align="center">96</td>
<td align="center">35</td>
<td align="center">53.0</td>
<td align="center">架构师</td>
</tr>
</tbody></table>
<p>我们得到了预测数据与各个样本间的距离，并按递增排好序。现假设 k = 3，对应的类别分别是“架构师”、“管理”、“管理”，按照算法实现的第 4 步，前 3 个点出现频率最高的类别是“管理”。那么，天蓝色的培养方向应该偏管理。</p>
<p>实例中 k 值取多少没有定论，如果实例中 k = 1 或 k = 2，那么结果未必是最准确的，这是一个经验值。通常 k 是 3 ≤ k &lt; 20 的整数，并且是奇数，这样避免出现相同票数。</p>
<p>回过头来看数据分布图，以你为中心画圆，其中圆 c1 也就是 k = 1，距你最近的是“架构师”，圆 c2 则是当 k = 3 的时候，其中三个“管理”，少数服从多数，统计最多的类别依然是“管理”。</p>
<h4 id="k-近邻算法优缺点"><a href="#k-近邻算法优缺点" class="headerlink" title="k 近邻算法优缺点"></a>k 近邻算法优缺点</h4><p>优点：精度高、对异常值不敏感、无数据输入假定。<br>缺点：kNN 必须保存全部数据集，会占用大量的存储空间，所以<strong>空间负责度高</strong>；kNN 必须对数据集中的每个数据计算距离值，实际使用时非常耗时，所以<strong>计算复杂度高</strong>。</p>
<h4 id="scikit-learn-简单实现"><a href="#scikit-learn-简单实现" class="headerlink" title="scikit-learn 简单实现"></a>scikit-learn 简单实现</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 导入 kNN 分类器</span></span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 实例化一个 k 为 3 的 kNN 分类器，默认为 5</span></span><br><span class="line">clf = KNeighborsClassifier(n_neighbors = <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 样本和测试数据集</span></span><br><span class="line">sample = np.array([</span><br><span class="line">    [<span class="number">43</span>,<span class="number">92</span>,<span class="string">&quot;管理&quot;</span>],</span><br><span class="line">    [<span class="number">60</span>,<span class="number">88</span>,<span class="string">&quot;管理&quot;</span>],</span><br><span class="line">    [<span class="number">69</span>,<span class="number">80</span>,<span class="string">&quot;架构师&quot;</span>],</span><br><span class="line">    [<span class="number">66</span>,<span class="number">78</span>,<span class="string">&quot;管理&quot;</span>],</span><br><span class="line">    [<span class="number">88</span>,<span class="number">50</span>,<span class="string">&quot;架构师&quot;</span>],</span><br><span class="line">    [<span class="number">80</span>,<span class="number">91</span>,<span class="string">&quot;管理&quot;</span>],</span><br><span class="line">    [<span class="number">96</span>,<span class="number">35</span>,<span class="string">&quot;架构师&quot;</span>],</span><br><span class="line">    [<span class="number">68</span>,<span class="number">80</span>,<span class="string">&quot;?&quot;</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 提取样本特征和标签进行训练</span></span><br><span class="line">X_train, y_train = sample[:-<span class="number">1</span>, :-<span class="number">1</span>], sample[:<span class="number">7</span>, -<span class="number">1</span>:].ravel()</span><br><span class="line">clf.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 提取测试集特征进行预测</span></span><br><span class="line">X_test = sample[-<span class="number">1</span>:, :-<span class="number">1</span>]</span><br><span class="line">result = clf.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> result[<span class="number">0</span>]</span><br></pre></td></tr></table></figure>
<p>执行输出：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[Running] python /Users/Fechin/work/ideaproj/td/test-ml/sklearn/knn2.py</span><br><span class="line"></span><br><span class="line">--------------------</span><br><span class="line">管理</span><br><span class="line"></span><br><span class="line">[Done] exited with code=0 in 0.834598 seconds</span><br></pre></td></tr></table></figure>

            <!--[if lt IE 9]><script>document.createElement('audio');</script><![endif]-->
            <audio id="audio" loop="1" preload="auto" controls="controls" data-autoplay="false">
                <source type="audio/mpeg" src="/static/mp3/%E6%80%80%E5%BF%B5%E9%9D%92%E6%98%A5.mp3">
            </audio>
            
        </div>
        
        
    <div id="gitalk-container" class="comment link"
		data-enable="true"
        data-ae="false"
        data-ci="a396afe529734b15300f"
        data-cs="0ae7c1790f9a5cbc2b7339c12a82d58fe58f9567"
        data-r="fechin.github.io"
        data-o="Fechin"
        data-a="Fechin"
        data-d="false"
    >查看评论</div>


    </div>
    
</div>


    </div>
</div>
</body>

<script src="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>


<script src="//lib.baomitu.com/jquery/1.8.3/jquery.min.js"></script>
<script src="/js/plugin.js"></script>
<script src="/js/typed.js"></script>
<script src="/js/diaspora.js"></script>


<link rel="stylesheet" href="/photoswipe/photoswipe.css">
<link rel="stylesheet" href="/photoswipe/default-skin/default-skin.css">


<script src="/photoswipe/photoswipe.min.js"></script>
<script src="/photoswipe/photoswipe-ui-default.min.js"></script>


<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">
    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>
    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">
        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>
        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">
            <div class="pswp__top-bar">
                <!--  Controls are self-explanatory. Order can be changed. -->
                <div class="pswp__counter"></div>
                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
                <button class="pswp__button pswp__button--share" title="Share"></button>
                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>
            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div> 
            </div>
            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>
            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>
            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>
        </div>
    </div>
</div>





<!-- Google Analytics -->
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-69833742-2"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-69833742-2');
</script>
<!-- End Google Analytics -->


</html>
